from flask import Flask, request, jsonify, send_from_directory
import openai
from chat_engine import load_chunks, build_vectorizer, search_best_chunk
import os

app = Flask(__name__)
openai.api_key = os.getenv("OPENAI_API_KEY")

chunks = load_chunks("data.txt")
vectorizer, vectors = build_vectorizer(chunks)

@app.route("/chat", methods=["POST"])
def chat():
    question = request.json.get("question")
    context = search_best_chunk(question, vectorizer, vectors, chunks)
    if not context:
        return jsonify({"answer": "Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin ph√π h·ª£p ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y."})

    messages = [
        {"role": "system", "content": f"Tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† c·ª• th·ªÉ d·ª±a tr√™n th√¥ng tin sau:\n\n{context}"},
        {"role": "user", "content": question}
    ]

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages,
        temperature=0.3,
        max_tokens=300
    )
    answer = response.choices[0].message["content"]
    return jsonify({"answer": answer})

# üëá PH·∫¶N GIAO DI·ªÜN WEB T·∫†I ƒê√ÇY
@app.route("/")
def serve_ui():
    return send_from_directory(".", "index.html")

@app.route("/style.css")
def serve_css():
    return send_from_directory(".", "style.css")

# if __name__ == "__main__":
#     port = int(os.environ.get("PORT", 5000))
#     app.run(host="0.0.0.0", port=port)
