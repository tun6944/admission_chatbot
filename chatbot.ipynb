{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-03T07:53:57.288359Z",
     "iopub.status.busy": "2025-06-03T07:53:57.288077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y langchain langchain-core langchain-community langchain-huggingface\n",
    "# !pip install -q langchain==0.1.14 langchain-community==0.0.34 langchain-core==0.1.50 langchain-huggingface==0.2.0 sentence-transformers transformers llama-cpp-python tf-keras faiss-cpu numpy==1.26.4 pandas==1.5.3 scikit-learn==1.2.2 ml-dtypes==0.4.0 flask huggingface-hub einops protobuf beautifulsoup4 torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install -q -U langchain langchain-core langchain-community langchain-huggingface sentence-transformers transformers llama-cpp-python tf-keras \n",
    "!pip install numpy==1.26.4 pandas==1.5.3 scikit-learn==1.2.2 ml-dtypes==0.4.0 flask huggingface-hub einops protobuf beautifulsoup4 qdrant-client torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121 # Ho·∫∑c cu118, cu126 t√πy theo m√¥i tr∆∞·ªùng Kaggle v√† driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "# Qdrant specific\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant # Import Qdrant vector store\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n v√† t√™n collection cho Qdrant trong m√¥i tr∆∞·ªùng Kaggle\n",
    "# Th∆∞ m·ª•c /kaggle/working/ l√† n∆°i c√≥ th·ªÉ ghi d·ªØ li·ªáu.\n",
    "qdrant_kaggle_path = \"/kaggle/working/qdrant_kaggle_store\"\n",
    "qdrant_collection_name_kaggle = \"huit_admissions_collection_kaggle\" # C√≥ th·ªÉ gi·ªØ t√™n gi·ªëng local ho·∫∑c th√™m suffix\n",
    "\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "device_type_kaggle = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs= {\"device\": device_type_kaggle}\n",
    ")\n",
    "\n",
    "print(f\"CUDA Available on Kaggle: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    # Ki·ªÉm tra VRAM (v√≠ d·ª•, kh√¥ng ph·∫£i l√† c√°ch ch√≠nh x√°c nh·∫•t nh∆∞ng cho √Ω t∆∞·ªüng)\n",
    "    # t = torch.cuda.get_device_properties(0)\n",
    "    # print(f\"Total VRAM: {t.total_memory / (1024**3):.2f} GB\")\n",
    "print(f\"Embedding model device: {embedding_model.client.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 3: Chu·∫©n b·ªã d·ªØ li·ªáu (Copy file t·ª´ Kaggle Datasets)\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# ƒêi·ªÅu ch·ªânh c√°c ƒë∆∞·ªùng d·∫´n n√†y cho ph√π h·ª£p v·ªõi dataset c·ªßa b·∫°n tr√™n Kaggle\n",
    "KAGGLE_INPUT_DATA_DIR = \"/kaggle/input/dataset-tuvantuyensinh\" # V√≠ d·ª•: /kaggle/input/your-dataset-slug\n",
    "KAGGLE_INPUT_MODEL_DIR = \"/kaggle/input/vinallama/gguf/default/1\" # V√≠ d·ª•: /kaggle/input/your-model-slug/path/to/gguf\n",
    "\n",
    "# Th∆∞ m·ª•c ƒë√≠ch trong kh√¥ng gian l√†m vi·ªác c·ªßa Kaggle (c√≥ th·ªÉ ghi)\n",
    "local_data_dir_kaggle = \"/kaggle/working/data\"\n",
    "local_models_dir_kaggle = \"/kaggle/working/models\"\n",
    "\n",
    "os.makedirs(local_data_dir_kaggle, exist_ok=True)\n",
    "os.makedirs(local_models_dir_kaggle, exist_ok=True)\n",
    "\n",
    "# Copy file .txt t·ª´ dataset ƒë·∫ßu v√†o\n",
    "if os.path.exists(KAGGLE_INPUT_DATA_DIR):\n",
    "    print(f\"üìÅ Files trong dataset ƒë·∫ßu v√†o ({KAGGLE_INPUT_DATA_DIR}): {os.listdir(KAGGLE_INPUT_DATA_DIR)}\")\n",
    "    for file_name in os.listdir(KAGGLE_INPUT_DATA_DIR):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            source_file = os.path.join(KAGGLE_INPUT_DATA_DIR, file_name)\n",
    "            dest_file = os.path.join(local_data_dir_kaggle, file_name)\n",
    "            shutil.copy(source_file, dest_file)\n",
    "    print(f\"‚úÖ ƒê√£ copy c√°c file .txt v√†o {local_data_dir_kaggle}\")\n",
    "else:\n",
    "    print(f\"[!] ƒê∆∞·ªùng d·∫´n dataset ƒë·∫ßu v√†o {KAGGLE_INPUT_DATA_DIR} kh√¥ng t·ªìn t·∫°i. H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ th√™m dataset v√†o notebook.\")\n",
    "\n",
    "# Copy model .gguf\n",
    "model_gguf_filename = \"vinallama-7b-chat_q5_0.gguf\" # T√™n file model c·ªßa b·∫°n\n",
    "gguf_source_path_kaggle = os.path.join(KAGGLE_INPUT_MODEL_DIR, model_gguf_filename)\n",
    "gguf_dest_path_kaggle = os.path.join(local_models_dir_kaggle, model_gguf_filename)\n",
    "model_GGUF_path_kaggle = None # S·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t\n",
    "\n",
    "if os.path.exists(gguf_source_path_kaggle):\n",
    "    print(f\"üìÅ File model GGUF t√¨m th·∫•y t·∫°i: {gguf_source_path_kaggle}\")\n",
    "    shutil.copy(gguf_source_path_kaggle, gguf_dest_path_kaggle)\n",
    "    model_GGUF_path_kaggle = gguf_dest_path_kaggle\n",
    "    print(f\"‚úÖ ƒê√£ copy model {model_gguf_filename} v√†o {local_models_dir_kaggle}\")\n",
    "else:\n",
    "    print(f\"[!] Model GGUF kh√¥ng t√¨m th·∫•y t·∫°i {gguf_source_path_kaggle}.\")\n",
    "    print(\"ƒêang th·ª≠ t·∫£i model t·ª´ HuggingFace Hub (c·∫ßn b·∫≠t Internet cho notebook)...\")\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    try:\n",
    "        # ƒê·∫£m b·∫£o repo_id v√† filename l√† ch√≠nh x√°c\n",
    "        downloaded_path = hf_hub_download(\n",
    "            repo_id=\"vilm/vinallama-7b-chat-GGUF\",\n",
    "            filename=model_gguf_filename,\n",
    "            local_dir=local_models_dir_kaggle,\n",
    "            local_dir_use_symlinks=False # T·ªët nh·∫•t cho Kaggle\n",
    "        )\n",
    "        model_GGUF_path_kaggle = downloaded_path # hf_hub_download tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß\n",
    "        print(f\"‚úÖ ƒê√£ t·∫£i model {model_gguf_filename} v√†o {model_GGUF_path_kaggle} t·ª´ Hub.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[!] L·ªói t·∫£i model t·ª´ Hub: {e}. Model s·∫Ω kh√¥ng kh·∫£ d·ª•ng.\")\n",
    "\n",
    "if not model_GGUF_path_kaggle or not os.path.exists(model_GGUF_path_kaggle):\n",
    "     print(f\"[!] QUAN TR·ªåNG: Kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng th·ªÉ t·∫£i file model GGUF {model_gguf_filename}. Chatbot s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "def remove_symbols_and_emojis(text):\n",
    "    \"\"\"Lo·∫°i b·ªè c√°c icon v√† emoji ph·ªï bi·∫øn.\"\"\"\n",
    "    text = text.replace(\"üî∞\", \"\")\n",
    "    text = text.replace(\"üî∂\", \"\")\n",
    "    text = text.replace(\"üî∏\", \"\")\n",
    "    \n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols & More\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def clean_text_content(text):\n",
    "    # L∆∞·ª£c b·ªè ƒëo·∫°n t·ª´ \"üî∞ Ph∆∞∆°ng th·ª©c tuy·ªÉn sinh:\" ƒë·∫øn tr∆∞·ªõc \"üî∞ T·ªï h·ª£p x√©t tuy·ªÉn:\"\n",
    "    text = re.sub(\n",
    "        r\"Ph∆∞∆°ng th·ª©c tuy·ªÉn sinh:.*?(?=T·ªï h·ª£p x√©t tuy·ªÉn:)\", \n",
    "        \"\", \n",
    "        text, \n",
    "        flags=re.DOTALL\n",
    "    )\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    # Lo·∫°i b·ªè footer (n·∫øu c√≥)\n",
    "    # text = re.split(r\"---\", text, flags=re.IGNORECASE)[0]\n",
    "    text = re.split(r\"5. QUY·ªÄN L·ª¢I C·ª¶A NG∆Ø·ªúI H·ªåC\", text, flags=re.IGNORECASE)[0]\n",
    "    # Lo·∫°i b·ªè icon v√† emoji\n",
    "    text = remove_symbols_and_emojis(text)\n",
    "    # Thay th·∫ø tab b·∫±ng d·∫•u c√°ch\n",
    "    text = text.replace('\\t', ' ').strip()\n",
    "    return text.strip()\n",
    "\n",
    "def remove_accents(text):\n",
    "    \"\"\"T·∫°o t√™n file .txt lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát.\"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', text)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def slugify(text):\n",
    "    \"\"\"Chuy·ªÉn text th√†nh t√™n file h·ª£p l·ªá (slug).\"\"\"\n",
    "    text = remove_accents(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s-]', '', text) # Ch·ªâ gi·ªØ ch·ªØ, s·ªë, kho·∫£ng tr·∫Øng, g·∫°ch ngang\n",
    "    text = re.sub(r'\\s+', ' ', text) # Thay kho·∫£ng tr·∫Øng b·∫±ng _\n",
    "    text = re.sub(r'\\n\\n+', '\\n', text) # Thay nhi·ªÅu \\n\\n b·∫±ng 1 \\n\n",
    "    return text.strip()\n",
    "\n",
    "def crawl_page(url):\n",
    "    print(f\">>> ƒêang crawl: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, headers = headers, timeout=15)\n",
    "        response.raise_for_status() # B√°o l·ªói n·∫øu request kh√¥ng th√†nh c√¥ng\n",
    "        response.encoding = \"utf-8\"\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        title_tag = soup.find(\"h1\", class_=\"article-title\")\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"unknown_title\"\n",
    "\n",
    "        main_table = soup.find(\"table\", class_=\"MsoNormalTable\")\n",
    "        \n",
    "        raw_text = \"\"\n",
    "        if main_table:\n",
    "            print(\"    -> T√¨m th·∫•y MsoNormalTable. ƒêang l·∫•y text...\")\n",
    "            raw_text = main_table.get_text(strip=False)\n",
    "        else:\n",
    "            print(\"    -> Kh√¥ng th·∫•y MsoNormalTable, th·ª≠ 'post-body'...\")\n",
    "            post_body = soup.find(\"div\", class_=\"post-body\")\n",
    "            if post_body:\n",
    "                raw_text = post_body.get_text(strip=False)\n",
    "            else:\n",
    "                print(f\"    [!] Kh√¥ng t√¨m th·∫•y n·ªôi dung ch√≠nh t·∫°i: {url}\")\n",
    "                return None # Tr·∫£ v·ªÅ None n·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c n·ªôi dung\n",
    "\n",
    "        noidung = clean_text_content(raw_text)\n",
    "\n",
    "        # T√¨m M√£ ng√†nh b·∫±ng Regex\n",
    "        ma_nganh = None\n",
    "        match = re.search(r\"M√É NG√ÄNH:\\s*(\\d{7})\", noidung, re.IGNORECASE)\n",
    "        if match:\n",
    "            ma_nganh = match.group(1)\n",
    "            print(f\"    -> T√¨m th·∫•y M√£ ng√†nh: {ma_nganh}\")\n",
    "        else:\n",
    "            print(\"    -> Kh√¥ng t√¨m th·∫•y M√£ ng√†nh b·∫±ng Regex.\")\n",
    "            \n",
    "        return {            \n",
    "            # \"url\": url,\n",
    "            \"ma_nganh\": ma_nganh,\n",
    "            \"title\": title,\n",
    "            \"noidung\": noidung\n",
    "        }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[!] L·ªói Request khi crawl {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[!] L·ªói kh√¥ng x√°c ƒë·ªãnh khi crawl {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def crawl_all(urls, output_dir=\"data\"):\n",
    "    \"\"\"Crawl t·∫•t c·∫£ URL v√† l∆∞u v√†o th∆∞ m·ª•c 'data'.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for idx, url in enumerate(urls):\n",
    "        data = crawl_page(url)\n",
    "        if data and data[\"noidung\"]: # Ch·ªâ l∆∞u n·∫øu c√≥ d·ªØ li·ªáu\n",
    "            filename = f\"{slugify(data['title'])}.txt\"\n",
    "            path = os.path.join(output_dir, filename)\n",
    "\n",
    "            with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "                # f.write(f\"URL: {data['url']}\\n\")\n",
    "                # f.write(f\"M√£ ng√†nh: {data['ma_nganh'] if data['ma_nganh'] else 'Kh√¥ng t√¨m th·∫•y'}\\n\\n\")\n",
    "                f.write(data[\"noidung\"])\n",
    "\n",
    "            print(f\"     ƒê√£ l∆∞u: {filename}\")\n",
    "        else:\n",
    "            print(f\"     B·ªè qua URL (Kh√¥ng c√≥ d·ªØ li·ªáu): {url}\")\n",
    "        print(\"-\" * 20) # Th√™m d√≤ng ph√¢n c√°ch cho d·ªÖ nh√¨n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    danh_sach_url = [\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-cong-nghe-thong-tin\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-marketing\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-ke-toan\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-cong-nghe-ky-thuat-co-dien-tu\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-tai-chinh-ngan-hang\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-cong-nghe-sinh-hoc\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-luat-kinh-te\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-logistic-va-quan-ly-chuoi-cung-ung\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-thuong-mai-dien-tu\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-cong-nghe-vat-lieu\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-kinh-doanh-quoc-te\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-cong-nghe-ky-thuat-hoa-hoc\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-quan-ly-tai-nguyen-va-moi-truong\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-quan-tri-khach-san\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-cong-nghe-det-may\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-quan-tri-kinh-doanh\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-quan-tri-dich-vu-du-lich-va-lu-hanh\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-cong-nghe-ky-thuat-dieu-khien-va-tu-dong-hoa\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-tai-chinh-ngan-hang\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-ngon-ngu-anh\",\n",
    "        \"https://ts.huit.edu.vn/nganh-dh/nganh-an-toan-thong-tin\",\n",
    "    ]\n",
    "    crawl_all(danh_sach_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 5: T·∫°o Vector Database (Qdrant)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# C·∫•u h√¨nh chunk (gi·ªëng nh∆∞ prepare_vector_db.py)\n",
    "CHUNK_CONFIG_KAGGLE = {\n",
    "    \"default\": {\"size\": 2000, \"overlap\": 500},\n",
    "    \"gioi-thieu-chung.txt\": {\"size\": 600, \"overlap\": 90},\n",
    "    \"thu-tuc-nhap-hoc.txt\": {\"size\": 500, \"overlap\": 80},\n",
    "    \"diem-chuan-2024.txt\": {\"size\": 500, \"overlap\": 80}\n",
    "}\n",
    "def get_chunk_config_kaggle(filename):\n",
    "    base_filename = os.path.basename(filename)\n",
    "    return CHUNK_CONFIG_KAGGLE.get(base_filename, CHUNK_CONFIG_KAGGLE[\"default\"])\n",
    "\n",
    "def create_db_from_files_kaggle(data_directory, embedding_model_instance, qdrant_db_path, qdrant_collection):\n",
    "    if not os.path.exists(data_directory):\n",
    "        print(f\"Th∆∞ m·ª•c d·ªØ li·ªáu {data_directory} kh√¥ng t·ªìn t·∫°i\")\n",
    "        return None\n",
    "\n",
    "    print(\"B·∫Øt ƒë·∫ßu t·∫°o vector store Qdrant t·ª´ c√°c file trong Kaggle...\")\n",
    "    all_chunks = []\n",
    "    file_paths = [os.path.join(data_directory, f) for f in os.listdir(data_directory) if f.endswith(\".txt\") and os.path.isfile(os.path.join(data_directory, f))]\n",
    "\n",
    "    if not file_paths:\n",
    "        print(f\"Kh√¥ng t√¨m th·∫•y file .txt n√†o trong {data_directory}\")\n",
    "        return None\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\" ƒêang x·ª≠ l√Ω {filename}...\")\n",
    "        try:\n",
    "            loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "            documents = loader.load()\n",
    "            if not documents:\n",
    "                print(f\"    Kh√¥ng c√≥ n·ªôi dung trong file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            config = get_chunk_config_kaggle(filename)\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=config[\"size\"], chunk_overlap=config[\"overlap\"]\n",
    "            )\n",
    "            chunks_from_file = text_splitter.split_documents(documents)\n",
    "            all_chunks.extend(chunks_from_file)\n",
    "            print(f\" ƒê√£ chia {filename} th√†nh {len(chunks_from_file)} chunks.\")\n",
    "        except Exception as e:\n",
    "            print(f\" L·ªói khi x·ª≠ l√Ω file {filename}: {e}\")\n",
    "\n",
    "    if not all_chunks:\n",
    "        print(\"Kh√¥ng c√≥ chunks n√†o ƒë∆∞·ª£c t·∫°o. D·ª´ng l·∫°i.\")\n",
    "        return None\n",
    "    print(f\"\\nT·ªïng s·ªë ƒëo·∫°n ƒë√£ chia: {len(all_chunks)}\")\n",
    "\n",
    "    print(\"ƒêang t·∫°o vector store Qdrant...\")\n",
    "    try:\n",
    "        # ƒê·∫£m b·∫£o th∆∞ m·ª•c qdrant_kaggle_path t·ªìn t·∫°i ƒë·ªÉ Qdrant l∆∞u tr·ªØ file\n",
    "        os.makedirs(qdrant_db_path, exist_ok=True)\n",
    "        print(f\"Th∆∞ m·ª•c l∆∞u tr·ªØ Qdrant: {qdrant_db_path}\")\n",
    "\n",
    "        qdrant_db = Qdrant.from_documents(\n",
    "            documents=all_chunks,\n",
    "            embedding=embedding_model_instance, # S·ª≠ d·ª•ng instance embedding_model ƒë√£ t·∫°o\n",
    "            path=qdrant_db_path, # Cho l∆∞u tr·ªØ c·ªë ƒë·ªãnh trong th∆∞ m·ª•c c√≥ th·ªÉ ghi c·ªßa Kaggle\n",
    "            collection_name=qdrant_collection,\n",
    "            force_recreate=True # T·∫°o l·∫°i n·∫øu ƒë√£ t·ªìn t·∫°i, ƒë·ªÉ ƒë·∫£m b·∫£o s·∫°ch s·∫Ω m·ªói l·∫ßn ch·∫°y tr√™n Kaggle\n",
    "        )\n",
    "        print(f\"Vector store Qdrant ƒë∆∞·ª£c t·∫°o v√† l∆∞u t·∫°i: {qdrant_db_path}, collection: {qdrant_collection}\")\n",
    "        return qdrant_db\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói khi t·∫°o Qdrant DB tr√™n Kaggle: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# T·∫°o DB Qdrant tr√™n Kaggle\n",
    "# embedding_model ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o ·ªü Cell 2\n",
    "db_instance_kaggle = None\n",
    "if os.listdir(local_data_dir_kaggle): # Ch·ªâ t·∫°o DB n·∫øu c√≥ file txt\n",
    "    db_instance_kaggle = create_db_from_files_kaggle(\n",
    "        local_data_dir_kaggle,\n",
    "        embedding_model,\n",
    "        qdrant_kaggle_path,\n",
    "        qdrant_collection_name_kaggle\n",
    "    )\n",
    "    if db_instance_kaggle:\n",
    "        print(\"T·∫°o DB Qdrant tr√™n Kaggle th√†nh c√¥ng.\")\n",
    "    else:\n",
    "        print(\"T·∫°o DB Qdrant tr√™n Kaggle th·∫•t b·∫°i. Ki·ªÉm tra l·ªói.\")\n",
    "else:\n",
    "    print(f\"Th∆∞ m·ª•c {local_data_dir_kaggle} tr·ªëng, kh√¥ng t·∫°o vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 6: Logic Chatbot (S·ª≠ d·ª•ng Qdrant v√† thi·∫øt l·∫≠p n_gpu_layers cho T4)\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# C√°c bi·∫øn ƒë√£ ƒë·ªãnh nghƒ©a:\n",
    "# model_GGUF_path_kaggle (t·ª´ Cell 3)\n",
    "# embedding_model (t·ª´ Cell 2)\n",
    "# qdrant_kaggle_path, qdrant_collection_name_kaggle (t·ª´ Cell 2)\n",
    "\n",
    "general_temperature_kaggle = 0.01\n",
    "max_token_output_kaggle = 512\n",
    "retrieval_k_value_kaggle = 4 # S·ªë l∆∞·ª£ng t√†i li·ªáu truy xu·∫•t (t∆∞∆°ng t·ª± faiss_search)\n",
    "\n",
    "def read_vectors_db_kaggle(persistent_path, collection_name_str, embeddings_instance):\n",
    "    print(f\"ƒêang t·∫£i vector database Qdrant t·ª´: {persistent_path}, collection: {collection_name_str}\")\n",
    "    try:\n",
    "        if not os.path.exists(persistent_path) or not os.listdir(persistent_path):\n",
    "             print(f\"L·ªñI: ƒê∆∞·ªùng d·∫´n Qdrant {persistent_path} kh√¥ng t·ªìn t·∫°i ho·∫∑c tr·ªëng. Collection c√≥ th·ªÉ ch∆∞a ƒë∆∞·ª£c t·∫°o.\")\n",
    "             return None\n",
    "\n",
    "        client = QdrantClient(path=persistent_path) # Cho l∆∞u tr·ªØ tr√™n ƒëƒ©a\n",
    "        \n",
    "        # Ki·ªÉm tra collection\n",
    "        try:\n",
    "            collection_info = client.get_collection(collection_name=collection_name_str)\n",
    "            print(f\"Th√¥ng tin collection Qdrant: {collection_info}\")\n",
    "            if collection_info.points_count == 0:\n",
    "                 print(f\"C·∫¢NH B√ÅO: Collection Qdrant '{collection_name_str}' tr·ªëng.\")\n",
    "        except Exception as e:\n",
    "            print(f\"L·ªñI: Kh√¥ng th·ªÉ l·∫•y th√¥ng tin collection '{collection_name_str}'. L·ªói: {e}\")\n",
    "            client.close()\n",
    "            return None\n",
    "\n",
    "\n",
    "        qdrant_store = Qdrant(\n",
    "            client=client, # client s·∫Ω ƒë∆∞·ª£c qu·∫£n l√Ω (ƒë√≥ng) b·ªüi instance Qdrant khi kh√¥ng c√≤n d√πng\n",
    "            collection_name=collection_name_str,\n",
    "            embeddings=embeddings_instance\n",
    "        )\n",
    "        print(\"ƒê√£ k·∫øt n·ªëi t·ªõi vector database Qdrant tr√™n Kaggle.\")\n",
    "        return qdrant_store\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói khi t·∫£i Qdrant DB tr√™n Kaggle: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def load_llm_kaggle(model_path_gguf_kaggle):\n",
    "    # ƒê·ªëi v·ªõi Kaggle T4 GPU (th∆∞·ªùng c√≥ 16GB VRAM):\n",
    "    # VinaLLaMA-7B (d·ª±a tr√™n Llama 2) c√≥ 32 layers.\n",
    "    # - ƒê·∫∑t `n_gpu_layers = -1` s·∫Ω c·ªë g·∫Øng offload t·∫•t c·∫£ c√°c layer c√≥ th·ªÉ l√™n GPU.\n",
    "    # - Ho·∫∑c ƒë·∫∑t b·∫±ng s·ªë layer th·ª±c t·∫ø (v√≠ d·ª•: 32 cho Llama 7B).\n",
    "    # V·ªõi 16GB VRAM, m·ªôt model Q5_0 7B (kho·∫£ng 4.375GB cho tr·ªçng s·ªë) n√™n v·ª´a ho√†n to√†n tr√™n GPU,\n",
    "    # c·ªông th√™m b·ªô nh·ªõ cho context v√† activations.\n",
    "    #\n",
    "    # N·∫øu Kaggle cung c·∫•p T4 x2, Llama.cpp (phi√™n b·∫£n Python bindings c∆° b·∫£n) th∆∞·ªùng ch·ªâ s·ª≠ d·ª•ng 1 GPU\n",
    "    # cho m·ªôt ti·∫øn tr√¨nh LLM. N·∫øu b·∫°n mu·ªën s·ª≠ d·ª•ng c·∫£ 2 GPU, c·∫ßn c√°c thi·∫øt l·∫≠p ph·ª©c t·∫°p h∆°n\n",
    "    # (v√≠ d·ª•: model parallelism v·ªõi th∆∞ vi·ªán kh√°c ho·∫∑c ch·∫°y 2 instance LlamaCpp ri√™ng bi·ªát).\n",
    "    # Gi·∫£ s·ª≠ ·ªü ƒë√¢y ch√∫ng ta d√πng 1 GPU T4.\n",
    "    n_gpu_layers_t4 = -1 # Offload t·∫•t c·∫£ c√°c layer c√≥ th·ªÉ l√™n GPU. Ho·∫∑c th·ª≠ 32.\n",
    "\n",
    "    if not model_path_gguf_kaggle or not os.path.exists(model_path_gguf_kaggle):\n",
    "        print(f\"L·ªói: Kh√¥ng t√¨m th·∫•y file model GGUF t·∫°i {model_path_gguf_kaggle}\")\n",
    "        return None\n",
    "\n",
    "    llm = LlamaCpp(\n",
    "        model_path=model_path_gguf_kaggle,\n",
    "        n_gpu_layers=n_gpu_layers_t4,\n",
    "        n_ctx=4096,\n",
    "        n_batch=512, # C√≥ th·ªÉ c·∫ßn gi·∫£m n·∫øu g·∫∑p v·∫•n ƒë·ªÅ v·ªÅ VRAM, nh∆∞ng 512 th∆∞·ªùng ·ªïn cho T4\n",
    "        max_tokens=max_token_output_kaggle,\n",
    "        temperature=general_temperature_kaggle,\n",
    "        top_p=0.9,\n",
    "        use_mlock=True,\n",
    "        use_mmap=True,\n",
    "        f16_kv=True, # T4 h·ªó tr·ª£ t·ªët FP16\n",
    "        verbose=True # ƒê·∫∑t True ƒë·ªÉ xem th√™m th√¥ng tin, False ƒë·ªÉ output g·ªçn h∆°n\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "def create_prompt_kaggle(template_str):\n",
    "    return PromptTemplate(template=template_str, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "def create_qa_chain_kaggle(prompt_obj, llm_obj, db_obj):\n",
    "    retriever = db_obj.as_retriever(search_kwargs={\"k\": retrieval_k_value_kaggle})\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm_obj,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True, # H·ªØu √≠ch ƒë·ªÉ debug, xem context n√†o ƒë∆∞·ª£c l·∫•y\n",
    "        chain_type_kwargs={'prompt': prompt_obj}\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "# --- Th·ª±c thi ch√≠nh cho truy v·∫•n chatbot ---\n",
    "if model_GGUF_path_kaggle and os.path.exists(model_GGUF_path_kaggle) and db_instance_kaggle:\n",
    "    print(\"B·∫Øt ƒë·∫ßu ƒë·ªçc database Qdrant (Kaggle) cho truy v·∫•n...\")\n",
    "    # S·ª≠ d·ª•ng c√πng instance embedding_model ƒë√£ d√πng ƒë·ªÉ t·∫°o DB\n",
    "    # Ho·∫∑c c√≥ th·ªÉ g·ªçi l·∫°i read_vectors_db_kaggle n·∫øu db_instance_kaggle kh√¥ng ƒë∆∞·ª£c tr·∫£ v·ªÅ ƒë√∫ng c√°ch\n",
    "    # db_for_query_kaggle = read_vectors_db_kaggle(qdrant_kaggle_path, qdrant_collection_name_kaggle, embedding_model)\n",
    "    db_for_query_kaggle = db_instance_kaggle # N·∫øu create_db_from_files_kaggle tr·∫£ v·ªÅ instance Qdrant\n",
    "\n",
    "    if db_for_query_kaggle:\n",
    "        print(\"ƒê√£ t·∫£i/s·ª≠ d·ª•ng th√†nh c√¥ng vector database Qdrant (Kaggle).\")\n",
    "\n",
    "        question_kaggle = \"H·ªçc ph√≠ 1 t√≠n ch·ªâ l√† bao nhi√™u?\" # C√¢u h·ªèi th·ª≠ nghi·ªám c·ªßa b·∫°n\n",
    "        print(f\"\\nC√¢u h·ªèi: {question_kaggle}\")\n",
    "\n",
    "        print(\"\\nKi·ªÉm tra truy xu·∫•t context t·ª´ c√¢u h·ªèi (Qdrant)...\")\n",
    "        retrieved_docs_kaggle = db_for_query_kaggle.similarity_search(question_kaggle, k=retrieval_k_value_kaggle)\n",
    "        for i, doc_item in enumerate(retrieved_docs_kaggle):\n",
    "            print(f\"\\n--- K·∫øt qu·∫£ Qdrant (debug) {i+1} ---\\n{doc_item.page_content}\\nMetadata: {doc_item.metadata}\\n\")\n",
    "\n",
    "\n",
    "        print(\"T·∫£i m√¥ h√¨nh LLM (Kaggle)...\")\n",
    "        llm_instance_kaggle = load_llm_kaggle(model_GGUF_path_kaggle)\n",
    "\n",
    "        if llm_instance_kaggle:\n",
    "            template_rag_kaggle = \"\"\"<|im_start|>system\n",
    "                B·∫°n l√† m·ªôt tr·ª£ l√Ω t∆∞ v·∫•n tuy·ªÉn sinh. S·ª≠ d·ª•ng th√¥ng tin sau ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y nh·ªØng c√¢u ƒë·∫°i lo·∫°i nh∆∞ \"T·ª´ t·∫≠n ƒë√°y l√≤ng, t√¥i th·ª±c s·ª± xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong d·ªØ li·ªáu\", ƒë·ª´ng c·ªë b·ªãa ra c√¢u tr·∫£ l·ªùi, c≈©ng ƒë·ª´ng hallucinate. Tr·∫£ l·ªùi c√¢u h·ªèi b√™n d∆∞·ªõi:\n",
    "                {context}<|im_end|>\n",
    "                <|im_start|>user\n",
    "                {question}<|im_end|>\n",
    "                <|im_start|>assistant\"\"\"\n",
    "\n",
    "            print(\"\\nT·∫°o prompt t·ª´ template...\")\n",
    "            prompt_instance_kaggle = create_prompt_kaggle(template_rag_kaggle)\n",
    "\n",
    "            print(\"\\nT·∫°o chu·ªói LLM v·ªõi truy xu·∫•t RAG (Qdrant)...\")\n",
    "            llm_chain_instance_kaggle = create_qa_chain_kaggle(prompt_instance_kaggle, llm_instance_kaggle, db_for_query_kaggle)\n",
    "\n",
    "            print(\"\\nB·∫Øt ƒë·∫ßu tr·∫£ l·ªùi c√¢u h·ªèi...\")\n",
    "            answer_dict_kaggle = llm_chain_instance_kaggle.invoke({\"query\": question_kaggle})\n",
    "\n",
    "            print(\"\\n--- C√¢u tr·∫£ l·ªùi t·ª´ LLM ---\")\n",
    "            print(answer_dict_kaggle.get(\"result\", \"Kh√¥ng c√≥ k·∫øt qu·∫£\"))\n",
    "\n",
    "            print(\"\\n--- Ngu·ªìn t√†i li·ªáu tham kh·∫£o (n·∫øu c√≥) ---\")\n",
    "            if \"source_documents\" in answer_dict_kaggle and answer_dict_kaggle[\"source_documents\"]:\n",
    "                for idx, s_doc in enumerate(answer_dict_kaggle[\"source_documents\"]):\n",
    "                    print(f\"Ngu·ªìn {idx+1}: Metadata: {s_doc.metadata}\")\n",
    "                    print(f\"{s_doc.page_content[:300]}...\\n\") # In m·ªôt ƒëo·∫°n tr√≠ch\n",
    "            else:\n",
    "                print(\"Kh√¥ng c√≥ ngu·ªìn t√†i li·ªáu n√†o ƒë∆∞·ª£c tr·∫£ v·ªÅ ho·∫∑c ch√∫ng tr·ªëng.\")\n",
    "            print(\"-\" * 30)\n",
    "        else:\n",
    "            print(\"[!] Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh LLM tr√™n Kaggle.\")\n",
    "    else:\n",
    "        print(\"[!] Kh√¥ng th·ªÉ t·∫£i/s·ª≠ d·ª•ng vector database Qdrant tr√™n Kaggle.\")\n",
    "elif not model_GGUF_path_kaggle or not os.path.exists(model_GGUF_path_kaggle):\n",
    "    print(f\"[!] Kh√¥ng th·ªÉ th·ª±c hi·ªán RAG do model GGUF kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y ho·∫∑c kh√¥ng t·∫£i ƒë∆∞·ª£c: {model_GGUF_path_kaggle}\")\n",
    "elif not db_instance_kaggle:\n",
    "    print(f\"[!] Kh√¥ng th·ªÉ th·ª±c hi·ªán RAG do vector database (Qdrant) ch∆∞a ƒë∆∞·ª£c t·∫°o ho·∫∑c t·∫£i th√†nh c√¥ng.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"H·ªçc ph√≠ 1 t√≠n ch·ªâ l√† bao nhi√™u\"\n",
    "faiss_search = 4  # S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ t·ª´ FAISS\n",
    "print(\"B·∫Øt ƒë·∫ßu ƒë·ªçc database...\")\n",
    "db = read_vectors_db()\n",
    "print(\"ƒê√£ t·∫£i th√†nh c√¥ng vector database.\")\n",
    "\n",
    "print(\"Ki·ªÉm tra truy xu·∫•t context t·ª´ c√¢u h·ªèi\")\n",
    "docs = db.similarity_search(question, k=faiss_search)\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n--- K·∫øt qu·∫£ FAISS {i+1} ---\\n{doc.page_content}\\n\")\n",
    "\n",
    "print(\"T·∫£i m√¥ h√¨nh LLM...\")\n",
    "llm = load_llm(model_GGUF)\n",
    "\n",
    "template = \"\"\"<|im_start|>system\\n\n",
    "B·∫°n l√† m·ªôt tr·ª£ l√Ω t∆∞ v·∫•n tuy·ªÉn sinh. S·ª≠ d·ª•ng th√¥ng tin sau ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y nh·ªØng c√¢u ƒë·∫°i lo·∫°i nh∆∞ \"T·ª´ t·∫≠n ƒë√°y l√≤ng, t√¥i th·ª±c s·ª± xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong d·ªØ li·ªáu\", ƒë·ª´ng c·ªë b·ªãa ra c√¢u tr·∫£ l·ªùi, c≈©ng ƒë·ª´ng hallucinate. Tr·∫£ l·ªùi c√¢u h·ªèi b√™n d∆∞·ªõi\\n\n",
    "{context}<|im_end|>\\n\n",
    "<|im_start|>user\\n\n",
    "{question}<|im_end|>\\n\n",
    "<|im_start|>assistant\"\"\"\n",
    "\n",
    "print(\"T·∫°o prompt t·ª´ template...\")\n",
    "prompt = create_prompt(template)\n",
    "\n",
    "print(\"T·∫°o chu·ªói LLM v·ªõi truy xu·∫•t RAG...\")\n",
    "llm_chain = create_qa_chain(prompt, llm, db)\n",
    "\n",
    "# answer = llm_chain.invoke({\"query\": question})\n",
    "answer = llm_chain.invoke({\"query\": question})\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7575252,
     "sourceId": 12042286,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 243336855,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 365815,
     "modelInstanceId": 344522,
     "sourceId": 422779,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
